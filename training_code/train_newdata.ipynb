{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq,AutoTokenizer\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "model_dir = \"Qwen2.5-32B-Instruct-GPTQ-Int4\"\n",
    "\n",
    "### 加载模型和分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"round1_train_data.jsonl\"\n",
    "new_train_json_dir=\"round1_train_data_new.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    \"\"\"\n",
    "    将数据集进行预处理\n",
    "    \"\"\"\n",
    "    # global i\n",
    "    MAX_LENGTH = 512 \n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\n",
    "        f\"<|system|>\\n你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都是（close-world assumption）闭世界假设，即未观测事实都为假。请逐步分析问题并在最后一行输出答案，最后一行的格式为:答案是：A<|endoftext|>\\n<|user|>\\n{example['input']}<|endoftext|>\\n<|assistant|>\\n\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = (\n",
    "        instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    )\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    if len(input_ids) > MAX_LENGTH:  # 做一个截断\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "train_df = pd.read_json(new_train_json_dir, lines=True)\n",
    "data=pd.read_json(\"new_500_data.jsonl\", lines=True)     #模型预测的测试集（0.8622）\n",
    "# data=pd.read_json(\"/home/tom/fssd/code/app/new_testdata.jsonl\", lines=True)  #人工标注测试集\n",
    "new_data=pd.concat([train_df,data])\n",
    "data=pd.read_json(\"new_gpt4_data.jsonl\",lines=True) #gpt4 公开数据集100\n",
    "# data=pd.read_json(\"gpt_train_25000.jsonl\",lines=True) #gpt4 公开数据集25000条，取前5000条\n",
    "# data=data.head(5000) #和上面一行代码一起开，取前5000条数据\n",
    "new_data=pd.concat([new_data,data])\n",
    "new_data.reset_index(inplace=True)\n",
    "new_data.drop(\"index\",axis=1)\n",
    "# new_data=new_data.sample(int(len(new_data)*0.8))  #随机抽80%的数据\n",
    "train_ds = Dataset.from_pandas(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data=new_data.sample(int(len(new_data)*0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:在一个团队中，成员有不同的角色和技能，并且有明确的上下级关系。以下是团队成员名单和他们...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>549</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:有一组数字，分别为：2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>379</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:在一个数字游戏中，玩家需要根据给定的数字规则来计算分数。规则如下：\\n\\n1. 如果一...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>83</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:有6个国家分别为：日本、埃及、尼泊尔、俄罗斯、中国和不丹，其对应的首都分别为：东京、开...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>1067</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:在以下问题中，请根据给定的条件，选择正确答案。\\n\\n有一组特定的规则和操作如下：\\n...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1247</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:假设有如下连个点之间的无向图信息：\\n\\n- 点A与点B之间有一条路径长度为1；\\n-...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>223</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:在这个情景中，有三个人：Vincent、Marcellus和Mia。下列是关于他们的信...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:假设您有两组整数的列表：\\n\\n1. 第一组为 [2, 4, 7, 13, 63, 1...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>871</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:在一个印度板球联盟中，有多个球队参加比赛和互相竞争。以下是一些球队的表现情况的类别说明...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...</td>\n",
       "      <td>题目:有四个人：Bob、Mike、Jim 和 George，他们的身高分别是：\\n\\n- B...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2531 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                        instruction  \\\n",
       "52       52  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "1970    549  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "3128    379  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "1504     83  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "2488   1067  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "...     ...                                                ...   \n",
       "1247   1247  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "1644    223  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "90       90  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "2292    871  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "59       59  你是一个逻辑推理专家，擅长解决逻辑推理问题。以下是一个逻辑推理的题目，形式为单项选择题。所有...   \n",
       "\n",
       "                                                  input output  \n",
       "52    题目:在一个团队中，成员有不同的角色和技能，并且有明确的上下级关系。以下是团队成员名单和他们...      A  \n",
       "1970  题目:有一组数字，分别为：2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...      B  \n",
       "3128  题目:在一个数字游戏中，玩家需要根据给定的数字规则来计算分数。规则如下：\\n\\n1. 如果一...      C  \n",
       "1504  题目:有6个国家分别为：日本、埃及、尼泊尔、俄罗斯、中国和不丹，其对应的首都分别为：东京、开...      A  \n",
       "2488  题目:在以下问题中，请根据给定的条件，选择正确答案。\\n\\n有一组特定的规则和操作如下：\\n...      A  \n",
       "...                                                 ...    ...  \n",
       "1247  题目:假设有如下连个点之间的无向图信息：\\n\\n- 点A与点B之间有一条路径长度为1；\\n-...      B  \n",
       "1644  题目:在这个情景中，有三个人：Vincent、Marcellus和Mia。下列是关于他们的信...      C  \n",
       "90    题目:假设您有两组整数的列表：\\n\\n1. 第一组为 [2, 4, 7, 13, 63, 1...      D  \n",
       "2292  题目:在一个印度板球联盟中，有多个球队参加比赛和互相竞争。以下是一些球队的表现情况的类别说明...      C  \n",
       "59    题目:有四个人：Bob、Mike、Jim 和 George，他们的身高分别是：\\n\\n- B...      B  \n",
       "\n",
       "[2531 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20230dfdd988419ea040dc8be76a6d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"output_v1/qwen2_5_32B\", #记得每一次修改文件\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    logging_steps=500,\n",
    "    num_train_epochs=2,\n",
    "    save_steps=500,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\",\n",
    "    # fp16=True,\n",
    "    save_total_limit=3,\n",
    "    # seed=2024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6328' max='6328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6328/6328 3:37:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.672200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.498400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.422300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.384100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.254700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.187800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.172400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.158100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6328, training_loss=0.31921516989938226, metrics={'train_runtime': 13038.1141, 'train_samples_per_second': 0.485, 'train_steps_per_second': 0.485, 'total_flos': 8428866772205568.0, 'train_loss': 0.31921516989938226, 'epoch': 2.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(messages, model, tokenizer):\n",
    "    device = \"cuda\"\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=384,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "        # do_sample=False,\n",
    "        # temperature=0.7\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # print(response)\n",
    "     \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证训练集ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "34it [00:59,  1.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1421it [42:15,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_json(new_train_json_dir, lines=True)\n",
    "\n",
    "test_pred_list = []\n",
    "test_label_list=[]\n",
    "for index, row in tqdm(test_df.iterrows()):\n",
    "    instruction = row['instruction']\n",
    "    input_value = row['input']\n",
    "    test_label_list.append(row[\"output\"])\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{instruction}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{input_value}\"}\n",
    "    ]\n",
    "\n",
    "    response = predict(messages, model, tokenizer)\n",
    "    test_pred_list.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'D',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'B',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'D',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'D',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'D',\n",
       " 'D',\n",
       " 'D',\n",
       " 'D',\n",
       " 'D',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'E',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'E',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'E',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'D',\n",
       " 'D',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'D',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'D',\n",
       " 'D',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'D',\n",
       " 'A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'D',\n",
       " 'D',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'E',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9753694581280788"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_label_list,test_pred_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
